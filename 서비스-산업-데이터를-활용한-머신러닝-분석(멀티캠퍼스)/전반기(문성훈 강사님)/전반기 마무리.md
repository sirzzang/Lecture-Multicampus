# 1. R

* 배워야 하나요?
  * 통계 분석의 기반
  * 프로그래밍만 활용해서 data analysis 진행할 수 없을 수도.
  * 안 할 수 없음.

* 데이터 전처리: EDA ~ feture engineering
  * feature 간 관계.	
  * 버려야 할 컬럼,  합칠 수 있는 컬럼, ...
  * feature 너무 많을 때 문제 발생.

* 데이터 수집 방식(crawling, ...)
* 패키지 : dplyr, CONLP(word cloud-자연어처리), ...
* 데이터 적재 및 사용: 하둡(전통적으로), 스파크.
* 세미프로젝트 : 머신러닝은 없고, 데이터자체를 기반으로 어떤 의미있는 데이터를 끌어낼 것인가.
* 지금 다시 공부해야 하나요? : *Nono... 나중에 다시 하셈. 블로그, 마크다운, 책 등.*



## +) 프로그래밍 공부

* 빅데이터, 머신러닝 순수학문 아님. IT에 기반한 분야. 프로그래밍과 뗄 수 없음. 원래는 통계학에서 했지만, 제조업 등 실제 분야로 들어오는 도중이므로 프로그래밍 없이는 안 됨.

* 빅데이터, 인공지능이 IT와 접목되어 있기 때문에 프로그램 만들고 분석하려면 해야 함.

* 로직(if, while, for문, ...) : 문제 주면 기본 로직+자료구조(리스트,맵 등 단일) 활용해서 짤 수 있어야 함. ~ 상위 자료구조 + 알고리즘 : 이 알고리즘을 구현하려면 어떤 자료구조를 써야 한다는 방식이 있음.

  

## +) Git, Github

> 프로그래밍은 못해도 Git은 해야 한다.

* 쉬운 예제, 배운 내용을 정리해야 한다.
* 처음에는 명령어 기반으로 이해하자. : `git init` , `git push`, ...
* 이후에 툴을 사용한다. : `Colab`도 github 연동됨.
* git이 생활이 되도록 합시다.



# 2. Python

> 데이터 분석에 있어서 가장 쉬운 언어. 데이터를 기반으로 추론하고, 의미를 찾아내는 게 목적.
>
> 객체 지향 프로그래밍, 안정적인 시스템을 만드는 목적이 아니다. 유지 보수가 가능한 robust한 시스템을 만드는 것이 아니기 때문에 python이 제일 적합하다.



* 개발환경

  * `Anaconda Jupyter notebook`
    * 지금 coLab 쓰니까 이걸 할 필요가 있었을까?
    * 기본적인 사항(라이브러리가 필요하다는 개념 등)을 알고 colab과 같은 툴로 넘어가야 한다.
  * `coLab`: 지금 사용하고 있는 툴. 클라우드시스템 GPU로 빨리 돌아간다.
  * `AWS` : 전세계에서 가장 큰 클라우드웹시스템. 머신러닝 환경(`MLLab`) 제공.  가장 대표적인 클라우드환경.

* 문법 + 라이브러리 : 특히 `Pandas`, `Numpy`

* 통계적 데이터 분석 : 통계 기법 기반의 데이터 분석 방식.

  * 통계 이론  : 수학적 개념. `예) 이원분석, 일원분석, ANOVA, 포아송, ...`

    > 안 할 수는 없는데, 우선순위를 어디에 둘지 생각해야 한다.
    >
    > 데이터를 보는 시각, insight를 넓힐 수 있다.
    >
    > 공모전, 프로젝트 등 기술적인 구현을 생각해서 잠깐 미뤄뒀다. 나중에 `게딱지` 책으로.
    >
    > Regression, Classification.

  * 머신러닝 : 인공지능을 구현하기 위한 방안 중 하나.

    > 계속 발전하는 분야이기 때문에 새로운 방안이 계속 나온다.
    >
    > 딥러닝 : 머신러닝의 방안 중 하나. 머신러닝의 방안 중 하나로 neural network 사용.

    * 지도학습 : 우리 강의에서는 지도학습까지만 진행. label 붙어 있음.

      1) linear regression : data를 잘 표현하는 직선을 그림.

      	> logistic으로 넘어가기 위한 발판

      2) logistic regression : 0과 1로 판단. binary. 

      3) multinomial classification : logistic의 확장판.

      * multinomial을 딥러닝으로 구현 : CNN

    ---

    *(나중에 해야 할 것)*

    * 비지도학습 : label 없이 데이터만 들어가고, 그 데이터를 분류. 각각의 데이터가 어떤 그룹으로 묶이는지.
    * 강화학습 : 현재 state에서 다음 state로 넘어갈 때 어떤 게 가장 좋은지. `예) 알파고`
    * ...
    * 딥러닝 : 머신러닝 중 neural network 이용해서 진행.

  

---

> 이후 진행될 하반기 강의

---



# 3. Spark + SQL

* Apache에서 만든 오픈소스 프레임워크.

* 데이터를 저장해 놓고 필요한 부분만 뽑기 위함.

  

# 4. Feature Engineering

* 공모전을 통해 드는 생각: column이 너무 많다 + 합쳐야 되는데 방법이 없다 + ... 
* 방법론을 배우는데, 경우가 매우 많기 때문에 정답이 없다.



# 5. 신경망

* CNN, RNN, ... : 이 때는 `Keras` 이용할 것.



# 6. 기타

> 딥러닝이 망하면서 신경망 알고리즘 대체하기 위한 알고리즘들이 등장했다.

* SVM, 나이브 베이지언, Decision Tree, RF, ...

* 로지스틱과 유사한 역할을 함.

* 로지스틱은 텐서플로우로 전부 구현했는데, 여기서는 이제 이 알고리즘들이 어떻게 동작하는지, 어떤 라이브러리로 구현해야 하는지 배워야 함. 

  `예) SVM -> scikit 활용` 등.

* 데이터마다 적합한 모델이 다르다. 그렇지만 다 알고 쓸 수 없으니, 여러 모델 다 돌려보고 라이브러리로 어떻게 사용하는지 가장 결과가 잘 나오는 모델을 낸다.

