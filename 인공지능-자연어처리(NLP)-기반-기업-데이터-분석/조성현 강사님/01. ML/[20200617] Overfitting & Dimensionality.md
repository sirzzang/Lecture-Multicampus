# 과적합



![image-20200621155438042](images/image-20200621155438042.png)

 KNN 알고리즘에서는 k가 많아질수록, Decision Tree 알고리즘에서는 depth가 깊어질수록 모델이 훈련 데이터에만 적합하게 되는 현상을 관찰할 수 있었다.

 앞으로도 과적합 문제에 대해 신경써야 한다. 학습 데이터를 완벽하게 설명하지만, 새로운 데이터를 잘 설명하지 못한다면 예측 등 실생활에서 활용할 수 없기 때문이다. test set accuracy가 낮게 나타나는 현상을 경계하자.

![image-20200621155703019](images/image-20200621155703019.png)

 과적합 문제를 방지하기 위해 train dataset을 학습용과 검증용으로 분할한다. 이 때 train dataset에서의 학습용 데이터는 학습에 직접 사용되고, 검증용 데이터는 평가를 통해 적절한 규제항을 찾아감으로써 학습에 간접적으로 사용된다.

 이후 test dataset, 즉, 한 번도 보지 않은 데이터(학습에 전혀 사용되지 않은 데이터)을 가지고 최종적으로 성능을 평가하게 된다.





# 차원의 저주



 기계는 데이터 feature를 모두 공간 상의 한 축으로 이해한다. 따라서 feature가 많을수록, 컴퓨터가 인식하는 공간의 차원이 점점 늘어난다.

 그런데 feautre가 너무 많아지게 되면, 차원이 높지만 그 차원을 채우고 있는 데이터 포인트의 개수가 상대적으로 적어져 빈 공간이 많아지게 된다. 따라서 빈 공간이 많을수록 기계가 학습할 수 있는 데이터가 적어지게 된다. 차원이 추가됨으로써 빈 공간이 늘어날 때마다 기계가 경험할 수 있는 데이터가 줄어들고, 모델 성능이 낮아지게 되는데, 이를 **차원의 저주**라고 한다.

![image-20200621160529757](images/image-20200621160529757.png)

 이러한 차원의 저주 문제를 해결하기 위해서는 **1) 추가 데이터 확보**, **2) 차원 축소(*PCA, SVD*등)의 방법**을 사용할 수 있다. 가능하다면 추가적으로 데이터를 확보하는 것이 가장 좋다. feature는 데이터를 설명하는 것이기 때문에, 더 많은 측면에서 데이터를 설명하고 모델링에 활용할 수 있다면 좋은 것이다. 데이터 확보만 된다면 더 풍부하게 모델을 만들 수 있다는 것이다.

 그러나 문제는 그럴 수 없을 때다. 데이터를 얼마든지 수집할 수 있다면 feature를 추가하는 게 문제가 안 된다. 그런데 데이터가 제한적이고, 추가 확보가 어렵다면 아무 생각 없이 feature를 추가하면 안 된다. 차원이 늘어날수록 빈 공간은 기하급수적으로 증가하고, 추가 데이터의 양도 기하급수적으로 증가한다. 고민이 필요한 지점이다.



> *생각해볼 점*
>
> DACON 기후 센서 예측 문제 할 때, 학습용 데이터에 비해 feature가 많다는 생각을 했다. feature가 무엇인지 정확히 모르지만, 비슷한 데이터(기온, 강수량 등)를 측정하는 센서가 5개씩 되었는데, 데이터 수를 늘리기에는(혹은 oversampling) 어려움이 있었기 때문에, 차원축소를 적용해보는 게 어땠을까 하는 생각이 든다. 

