{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Chatbot-Transformers-DotProduct-practice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OupmbBZiyTEi",
        "colab_type": "text"
      },
      "source": [
        "일단 코드 쭉 연결시켜 보고 이해하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MpVlfGUyGEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, Dot\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6LSF_u8wHRR",
        "colab_type": "text"
      },
      "source": [
        "# Attention.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmZjXV50RVZf",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "# def _scaled_dot_product(qs, ks, vs):\n",
        "#     key_dim_per_head = key_dim // num_heads\n",
        "    \n",
        "#     o1 = tf.matmul(qs, ks, transpose_b=True) # Q * (K^T)\n",
        "#     o2 = o1 / (key_dim_per_head**0.5) # Q * (K^T)/(루트dk)\n",
        "#     tf\n",
        "#     if masked:\n",
        "#         diag_vals = tf.ones_like(o2) # batch_size, num_heads 축 없애고 mask 2차원으로 만듦.\n",
        "#         tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # 대각요소 위 무시.\n",
        "#         masks = tf.tile(input=tril[np.newaxis, np.newaxis, :, :],\n",
        "#                         multiples=[o2.shape[0], o2.shape[1], 1, 1]) # batch size, num_heads 만큼 mask 늘려 줌.\n",
        "#         paddings = tf.ones_like(masks) * -1e9\n",
        "#         o2 = tf.where(tf.equal(masks, 0), paddings, o2)\n",
        "    \n",
        "#     o3 = Activation('softmax')(o3)\n",
        "#     return tf.matmul(o3, vs)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxT14cVy2YTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _scaled_dot_product(qs, ks, vs, masked):\n",
        "    '''\n",
        "    qs, ks, vs: 4-D tensor (batch_size, num_heads, max_seq_len, dim)\n",
        "    masked: boolean\n",
        "    '''\n",
        "    print(qs.shape, ks.shape)\n",
        "    key_dim_per_head = linear_key_dim // num_heads\n",
        "\n",
        "    o1 = tf.matmul(qs, ks, transpose_b=True) # Q *a (K^T)\n",
        "    o2 = o1 / (key_dim_per_head**0.5) # Q * (K^T)/(루트dk)\n",
        "    \n",
        "    if masked:\n",
        "        diag_vals = tf.ones_like(o2[0, 0, :, :])\n",
        "        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # 하삼각행렬: 자기 자신인 단어까지만.\n",
        "        masks = tf.tile(input=tf.reshape(tril, (1, 1, tril.shape[0], tril.shape[1])),\n",
        "                        multiples=[tf.shape(o2)[0], tf.shape(o2)[1], 1, 1]) # batch size, num_heads 만큼 행렬 사이즈 늘려서 마스크 만듦.\n",
        "        paddings = tf.ones_like(masks) * -1e9 # 주목하지 말아야 할 부분에 낮은 숫자.\n",
        "        o2 = tf.where(tf.equal(masks, 0), paddings, o2) # mask에 0인 위치(뒤의 단어)에 패딩을 넣어 준다.\n",
        "\n",
        "    o3 = Activation('softmax')(o2) # softmax\n",
        "    o3 = tf.matmul(o3, vs)\n",
        "\n",
        "    return o3   "
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xvW9sDj693q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _concat_heads(outputs):\n",
        "    def transpose_then_concat_last_two_dimension(tensor):\n",
        "        tensor = tf.transpose(tensor, [0, 2, 1, 3])\n",
        "        t_shape = tensor.get_shape().as_list()\n",
        "        num_heads, dim = t_shape[-2:]\n",
        "        return tf.reshape(tensor, [-1] + t_shape[1:-2] + [num_heads * dim])\n",
        "    return transpose_then_concat_last_two_dimension(outputs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxrecBHt7i8o",
        "colab_type": "text"
      },
      "source": [
        "테스트 및 정리 요망\n",
        "- Keras Dot 연산 쓰니까 이상했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnmII_Ns7eGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "8a78698a-7327-4f5f-b709-5e9e66e045b4"
      },
      "source": [
        "# ones_like -> 차원 삭제\n",
        "tensor = tf.constant(np.arange(1, 13).reshape(1, 2, 2, 3))\n",
        "print(tensor)\n",
        "print(tf.ones_like(tensor[0, 0, :, :])) # 앞의 두 차원 사라짐."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[ 1  2  3]\n",
            "   [ 4  5  6]]\n",
            "\n",
            "  [[ 7  8  9]\n",
            "   [10 11 12]]]], shape=(1, 2, 2, 3), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[1 1 1]\n",
            " [1 1 1]], shape=(2, 3), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVy9Zu5j-kFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "f19ac33b-018f-4c95-a6de-bdd7173a6742"
      },
      "source": [
        "# linear operator shape 얻기\n",
        "tensor = [[1., 2.], [3., 4.]]\n",
        "tril = tf.linalg.LinearOperatorLowerTriangular(tensor).to_dense()\n",
        "print(tril.shape)\n",
        "print(tril.get_shape().as_list())  # 리스트로 해주려고...\n",
        "\n",
        "print(tril)\n",
        "# 위나 아래나 똑같다.\n",
        "print(tril[np.newaxis, np.newaxis, :, :])\n",
        "print(tf.reshape(tril,  [1, 1] + tril.get_shape().as_list()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2)\n",
            "[2, 2]\n",
            "tf.Tensor(\n",
            "[[1. 0.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1. 0.]\n",
            "   [3. 4.]]]], shape=(1, 1, 2, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[[1. 0.]\n",
            "   [3. 4.]]]], shape=(1, 1, 2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cErs9AHooYZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD3OG4067zfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "30d52614-a806-49a5-ea2a-209107bd5383"
      },
      "source": [
        "# input x multiple 차원만큼 shape된다.\n",
        "a = tf.constant([[1, 2, 3], [4, 5, 6]], tf.int32) # (2, 3)\n",
        "b = tf.constant([1, 2], tf.int32) # (2*1, 3*2) = (2, 6)\n",
        "c = tf.constant([2, 1], tf.int32) # (2*2, 3*1) = (4, 3)\n",
        "d = tf.constant([2, 2], tf.int32) # (2*2, 3*2) = (4, 6)\n",
        "e = tf.constant([1, 2, 2], tf.int32) # 오류나지 않을까? \n",
        "print(tf.tile(a, b))\n",
        "print(tf.tile(a, c))\n",
        "print(tf.tile(a, d))\n",
        "print(tf.tile(a, e)) # 오케 오류 났다."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3 1 2 3]\n",
            " [4 5 6 4 5 6]], shape=(2, 6), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [1 2 3]\n",
            " [4 5 6]], shape=(4, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2 3 1 2 3]\n",
            " [4 5 6 4 5 6]\n",
            " [1 2 3 1 2 3]\n",
            " [4 5 6 4 5 6]], shape=(4, 6), dtype=int32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-529240c3a35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(input, multiples, name)\u001b[0m\n\u001b[1;32m  11386\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11387\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11388\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11389\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11390\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected multiples argument to be a vector of length 2 but got length 3 [Op:Tile]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOUPDQIE97fX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "18b85fbf-6caa-4c6d-c436-0e50c69ba39a"
      },
      "source": [
        "from tensorflow.keras.layers import Multiply, multiply\n",
        "dk = 2\n",
        "Q_Kt = tf.constant([[15.402, 14.309, 12.622, 8.961, 7.433],\n",
        "                    [12.875, 11.969, 10.502, 7.402, 6.120],\n",
        "                    [11.866, 11.002, 9.856, 7.145, 5.976],\n",
        "                    [9.482, 8.778, 7.954, 5.852, 4.924],\n",
        "                    [9.642, 8.926, 8.096, 5.965, 5.021]],\n",
        "                    dtype=tf.float32)\n",
        "Q_Kt / dk**(0.5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[10.89086  , 10.117991 ,  8.925102 ,  6.3363843,  5.2559247],\n",
              "       [ 9.104    ,  8.463361 ,  7.4260354,  5.2340045,  4.3274937],\n",
              "       [ 8.39053  ,  7.7795887,  6.9692445,  5.052278 ,  4.22567  ],\n",
              "       [ 6.704787 ,  6.2069836,  5.6243277,  4.137989 ,  3.4817936],\n",
              "       [ 6.817924 ,  6.311635 ,  5.724736 ,  4.217892 ,  3.550383 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvaADEOXSzyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "abb95a8a-c795-4dfa-cd83-f799a8dc09eb"
      },
      "source": [
        "q = tf.constant([[4.134, 3.328],\n",
        "                 [3.567, 2.635],\n",
        "                 [2.885, 2.959],\n",
        "                 [2.129, 2.598],\n",
        "                 [2.147, 2.666]], dtype=tf.float32)\n",
        "k = tf.constant([[2.313, 1.754],\n",
        "                 [2.178, 1.584],\n",
        "                 [1.729, 1.645],\n",
        "                 [1.041, 1.399],\n",
        "                 [0.800, 1.239]])\n",
        "\n",
        "q[np.newaxis, :, :], k[np.newaxis, :, :].shape # dummy batch_shape\n",
        "Dot(axes=[2, 2])([q[np.newaxis, :, :], k[np.newaxis, :, :]]) # 이렇게 나와야 한다."
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=\n",
              "array([[[15.399253 , 14.275404 , 12.622246 ,  8.959366 ,  7.430592 ],\n",
              "        [12.872261 , 11.942766 , 10.501917 ,  7.399612 ,  6.118365 ],\n",
              "        [11.8630905, 10.970586 ,  9.8557205,  7.142926 ,  5.974201 ],\n",
              "        [ 9.481269 ,  8.752193 ,  7.954751 ,  5.850891 ,  4.922122 ],\n",
              "        [ 9.642175 ,  8.89911  ,  8.097733 ,  5.964761 ,  5.020774 ]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAL4KVwSYAZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "9737cbac-68f2-4f6e-e9e3-744b996498a9"
      },
      "source": [
        "q = tf.constant([[4.134, 3.328],\n",
        "                 [3.567, 2.635],\n",
        "                 [2.885, 2.959],\n",
        "                 [2.129, 2.598],\n",
        "                 [2.147, 2.666]], dtype=tf.float32)\n",
        "k = tf.constant([[2.313, 1.754],\n",
        "                 [2.178, 1.584],\n",
        "                 [1.729, 1.645],\n",
        "                 [1.041, 1.399],\n",
        "                 [0.800, 1.239]], dtype=tf.float32)\n",
        "v = tf.constant([[3.382, 4.593],\n",
        "                 [3.006, 3.579],\n",
        "                 [3.258, 4.015],\n",
        "                 [2.749, 3.627],\n",
        "                 [2.609, 3.605]], dtype=tf.float32)\n",
        "\n",
        "q = q[np.newaxis, np.newaxis, :, :]\n",
        "k = k[np.newaxis, np.newaxis, :, :]\n",
        "v = v[np.newaxis, np.newaxis, :, :]\n",
        "print(q.shape, k.shape, v.shape)\n",
        "_scaled_dot_product(q, k, v)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 5, 2) (1, 1, 5, 2) (1, 1, 5, 2)\n",
            "(1, 1, 5, 2) (1, 1, 5, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 5, 2), dtype=float32, numpy=\n",
              "array([[[[3.2595491, 4.248784 ],\n",
              "         [3.244916 , 4.2112794],\n",
              "         [3.2370493, 4.193578 ],\n",
              "         [3.213495 , 4.147224 ],\n",
              "         [3.2150795, 4.1502357]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTTLuYJgoiok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "c44625a0-6caf-485f-ffdd-c52b0da411d8"
      },
      "source": [
        "def _scaled_dot_product(qs, ks, vs, masked=True):\n",
        "    '''\n",
        "    qs: (batch_size, num_heads, max_seq_len, dim)\n",
        "    ks: (batch_size, num_heads, max_seq_len, dim)\n",
        "    vs: (batch_size, num_heads, max_seq_len, dim)\n",
        "    '''\n",
        "    print(qs.shape, ks.shape, vs.shape)\n",
        "    # key_dim_per_head = linear_key_dim // num_heads\n",
        "    key_dim_per_head = 2 # 테스트용\n",
        "\n",
        "    o1 = tf.matmul(qs, ks, transpose_b=True) # Q *a (K^T)\n",
        "    o2 = o1 / (key_dim_per_head**0.5) # Q * (K^T)/(루트dk)\n",
        "\n",
        "    print(\"----- o2 -----\")\n",
        "    print(o2.shape)\n",
        "    if masked:\n",
        "        diag_vals = tf.ones_like(o2[0, 0, :, :])\n",
        "        print(diag_vals)\n",
        "        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # 자기 자신까지만\n",
        "        print(tril.shape)\n",
        "        masks = tf.tile(input=tf.reshape(tril, (1, 1, tril.shape[0], tril.shape[1])),\n",
        "                        multiples=[tf.shape(o2).sh[0], o2.shape[1], 1, 1]) # batch size, num_heads 만큼 mask 늘려 줌.\n",
        "        print(f\"===== masks =======\")\n",
        "        print(masks)\n",
        "        print()\n",
        "        paddings = tf.ones_like(masks) * -1e9 # 주목하지 말아야 할 부분에 낮은 숫자 주고\n",
        "        print(f\"===== paddings ====\")\n",
        "        print(paddings)\n",
        "        print()\n",
        "        o2 = tf.where(tf.equal(masks, 0), paddings, o2) # mask에 0인 위치(뒤의 단어)에 패딩을 넣어 준다.\n",
        "        print(o2)\n",
        "\n",
        "    o3 = Activation('softmax')(o2) # softmax\n",
        "    o3 = tf.matmul(o3, vs)\n",
        "\n",
        "    return o3\n",
        "\n",
        "_scaled_dot_product(q, k, v)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1, 5, 2) (1, 1, 5, 2) (1, 1, 5, 2)\n",
            "----- o2 -----\n",
            "(1, 1, 5, 5)\n",
            "tf.Tensor(\n",
            "[[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]], shape=(5, 5), dtype=float32)\n",
            "(5, 5)\n",
            "===== masks =======\n",
            "tf.Tensor(\n",
            "[[[[1. 0. 0. 0. 0.]\n",
            "   [1. 1. 0. 0. 0.]\n",
            "   [1. 1. 1. 0. 0.]\n",
            "   [1. 1. 1. 1. 0.]\n",
            "   [1. 1. 1. 1. 1.]]]], shape=(1, 1, 5, 5), dtype=float32)\n",
            "\n",
            "===== paddings ====\n",
            "tf.Tensor(\n",
            "[[[[-1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09]\n",
            "   [-1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09]\n",
            "   [-1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09]\n",
            "   [-1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09]\n",
            "   [-1.e+09 -1.e+09 -1.e+09 -1.e+09 -1.e+09]]]], shape=(1, 1, 5, 5), dtype=float32)\n",
            "\n",
            "tf.Tensor(\n",
            "[[[[ 1.0888916e+01 -1.0000000e+09 -1.0000000e+09 -1.0000000e+09\n",
            "    -1.0000000e+09]\n",
            "   [ 9.1020632e+00  8.4448109e+00 -1.0000000e+09 -1.0000000e+09\n",
            "    -1.0000000e+09]\n",
            "   [ 8.3884716e+00  7.7573757e+00  6.9690471e+00 -1.0000000e+09\n",
            "    -1.0000000e+09]\n",
            "   [ 6.7042694e+00  6.1887355e+00  5.6248584e+00  4.1372046e+00\n",
            "    -1.0000000e+09]\n",
            "   [ 6.8180470e+00  6.2926211e+00  5.7259617e+00  4.2177229e+00\n",
            "     3.5502234e+00]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 5, 2), dtype=float32, numpy=\n",
              "array([[[[3.382    , 4.593    ],\n",
              "         [3.25365  , 4.2468643],\n",
              "         [3.2523253, 4.2100797],\n",
              "         [3.2254434, 4.1579413],\n",
              "         [3.2150795, 4.1502357]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATG3NpoDkXKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "94ef0094-e8c4-4b68-fea0-38df85fb247d"
      },
      "source": [
        "q # batch_size: 1, num_heads: 1, max_seq :5, dim = 2"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 5, 2), dtype=float32, numpy=\n",
              "array([[[[4.134, 3.328],\n",
              "         [3.567, 2.635],\n",
              "         [2.885, 2.959],\n",
              "         [2.129, 2.598],\n",
              "         [2.147, 2.666]]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGf3Lob7gfvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba4c237c-da25-43d6-87fe-cf3373583fde"
      },
      "source": [
        "tf.reshape(q, shape=(-1, q.shape[2], q.shape[1]*q.shape[3]))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1, 5, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnU_YEHkWjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _concat_heads(outputs):\n",
        "    def transpose_then_concat_last_two_dimension(tensor):\n",
        "        return tf.reshape(tensor, shape=(-1, tensor.shape[2], tensor.shape[1]*tensor.shape[3]))\n",
        "    return transpose_then_concat_last_two_dimension(outputs)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp9WIglaldYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f7227e49-78bb-40f6-b979-3946ad60bc23"
      },
      "source": [
        "_concat_heads(q)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
              "array([[[4.134, 3.328],\n",
              "        [3.567, 2.635],\n",
              "        [2.885, 2.959],\n",
              "        [2.129, 2.598],\n",
              "        [2.147, 2.666]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fcSrLb_uDm8",
        "colab_type": "text"
      },
      "source": [
        "o2 shape 주면 안된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77kLVR92uDPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TypeError                                 Traceback (most recent call last)\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\n",
        "    547     try:\n",
        "--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\n",
        "    549     except TypeError:\n",
        "\n",
        "11 frames\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py in <listcomp>(.0)\n",
        "    547     try:\n",
        "--> 548       str_values = [compat.as_bytes(x) for x in proto_values]\n",
        "    549     except TypeError:\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/compat.py in as_bytes(bytes_or_text, encoding)\n",
        "     86     raise TypeError('Expected binary or unicode string, got %r' %\n",
        "---> 87                     (bytes_or_text,))\n",
        "     88 \n",
        "\n",
        "TypeError: Expected binary or unicode string, got None\n",
        "\n",
        "During handling of the above exception, another exception occurred:\n",
        "\n",
        "TypeError                                 Traceback (most recent call last)\n",
        "<ipython-input-14-da5338f21150> in <module>()\n",
        "      5 \n",
        "      6 \n",
        "----> 7 decMaskedAttValue = _scaled_dot_product(decMaskedQs, decMaskedKs, decMaskedVs, key_dim, True)\n",
        "      8 decMaskedConAttValue = _concat_heads(decMaskedAttValue)\n",
        "      9 decMaskedConAttValue.shape\n",
        "\n",
        "<ipython-input-9-21994e08574a> in _scaled_dot_product(qs, ks, vs, key_dim, masked)\n",
        "     12         tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # 하삼각행렬: 자기 자신인 단어까지만.\n",
        "     13         masks = tf.tile(input=tf.reshape(tril, (1, 1, tril.shape[0], tril.shape[1])),\n",
        "---> 14                         multiples=[o2.shape[0], o2.shape[1], 1, 1]) # batch size, num_heads 만큼 행렬 사이즈 늘려서 마스크 만듦.\n",
        "     15         paddings = tf.ones_like(masks) * -1e9 # 주목하지 말아야 할 부분에 낮은 숫자.\n",
        "     16         o2 = tf.where(tf.equal(masks, 0), paddings, o2) # mask에 0인 위치(뒤의 단어)에 패딩을 넣어 준다.\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in tile(input, multiples, name)\n",
        "  11404   try:\n",
        "  11405     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
        "> 11406         \"Tile\", input=input, multiples=multiples, name=name)\n",
        "  11407   except (TypeError, ValueError):\n",
        "  11408     result = _dispatch.dispatch(\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\n",
        "    471         except TypeError as err:\n",
        "    472           if dtype is None:\n",
        "--> 473             raise err\n",
        "    474           else:\n",
        "    475             raise TypeError(\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\n",
        "    468               dtype=dtype,\n",
        "    469               as_ref=input_arg.is_ref,\n",
        "--> 470               preferred_dtype=default_dtype)\n",
        "    471         except TypeError as err:\n",
        "    472           if dtype is None:\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\n",
        "   1497 \n",
        "   1498     if ret is None:\n",
        "-> 1499       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
        "   1500 \n",
        "   1501     if ret is NotImplemented:\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\n",
        "    336                                          as_ref=False):\n",
        "    337   _ = as_ref\n",
        "--> 338   return constant(v, dtype=dtype, name=name)\n",
        "    339 \n",
        "    340 \n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\n",
        "    262   \"\"\"\n",
        "    263   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
        "--> 264                         allow_broadcast=True)\n",
        "    265 \n",
        "    266 \n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\n",
        "    280       tensor_util.make_tensor_proto(\n",
        "    281           value, dtype=dtype, shape=shape, verify_shape=verify_shape,\n",
        "--> 282           allow_broadcast=allow_broadcast))\n",
        "    283   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)\n",
        "    284   attrs = {\"value\": tensor_value, \"dtype\": dtype_value}\n",
        "\n",
        "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)\n",
        "    550       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n",
        "    551                       \"Contents: %s. Consider casting elements to a \"\n",
        "--> 552                       \"supported type.\" % (type(values), values))\n",
        "    553     tensor_proto.string_val.extend(str_values)\n",
        "    554     return tensor_proto\n",
        "\n",
        "TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 4, 1, 1]. Consider casting elements to a supported type."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}