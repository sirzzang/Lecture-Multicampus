{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(binary classification)\n",
    "\n",
    "* 1) 지도학습 중, 데이터의 label(y값)이 0 혹은 1로 설정되는 유형의 학습을 의미한다.\n",
    "* 2) 기존의 선형회귀방식으로 학습하고 예측하는 것이 불가하므로, 가설의 형태를 바꾸어 학습해야 한다.\n",
    "* 3) 다중선형회귀 모형에서 직선(H = XW + b) 형태의 가설을 사용했다면, 로지스틱회귀 모형에서는 **0에서 1 사이의 값**을 가지는 함수로 가설을 표현한다. 그러한 함수를 **sigmoid 함수**라고 한다\n",
    "* 4) 또한, binary classification부터는 정확도를 측정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sigmoid 함수\n",
    "\n",
    "* 1) 가설의 형태가 linear인지 logistic인지 판단한다.\n",
    "    (linear라면 linear regression 사용)\n",
    "\n",
    "* 2) logistic이면 sigmoid함수를 이용해 hypothesis를 설정하고, 새로운 H를 구한다.\n",
    "    -> 가설이 변경되었기 때문에, 해당 가설을 이용한 cost 함수를 이용하면 local minima(minimum)를 찾게 될 수도 있다.\n",
    "\n",
    "* 3) 따라서, 가설이 변경됨에 따라 **cost 함수도 변경**해야 한다.\n",
    "-> 수학식 이용\n",
    "#### cost = -ylog(H) - (1-y)log(1-H)\n",
    "-> y = 0일 때와 y = 1일 때 한 번에 나타내는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid 함수의 그래프를 그려보자\n",
    "f(x) = 1 / (1 + e **(-x))\n",
    "\n",
    "* 0과 1에 점근하는 형태로 그려짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26f5e130e10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXAklEQVR4nO3dfZBdd33f8ffXqxWRCEUiEo2th8hMFDd2aMaw47ilD04hWPbEkkMJkZtMSWCiSVu3zYR6ag+M7ZjMpKChnXTihKqEITAU4xCy2TBiNm7iTGY6MbXM+gHZbFkcB+/KxYJYTomFLdnf/nHPwvXde/ee3T336dz3a2ZH957z23t+e+7VZ3/7ezgnMhNJ0ui7YNAVkCRVw0CXpJow0CWpJgx0SaoJA12SamLToA68Y8eO3Ldv36AOL0kj6YEHHvhGZu5st29ggb5v3z5OnDgxqMNL0kiKiL/qtM8uF0mqCQNdkmrCQJekmjDQJakmDHRJqgkDXZJqwkCXpJow0CWpJrouLIqIjwI/CTydmT/SZn8AvwFcCzwH/HxmfrHqikqqh+m5JW6fOcmZs+dW7Lsg4KWEAPp1p4Z+HXP5OBMRvJjJrm1buOnqS7j+8l2VHaPMStGPAb8JfLzD/muA/cXXjwG/XfwrqaZWC+WNeKlI1H7edqdfx1w+zovFTYWWzpzlls8+AlBZqHcN9Mz884jYt0qRQ8DHs3Hro/siYltEXJiZT1VSQ0l91xrYg2g5j4Oz517k6Ox8/wK9hF3Ak03PF4ttKwI9Io4ARwD27t1bwaElbdT03BJHZ+dZOnO2Y2APouU8Lk6dOVvZa1UR6NFmW9v3PTOPAccApqam/GxIA9Ic4s38T9l/F23bUtlrVRHoi8Cepue7gVMVvK6kCnUKcQ3OlskJbrr6ksper4pAnwFujIi7aAyGPmv/uTQcRi3EneWyMWWmLX4KuArYERGLwG3AJEBmfhg4TmPK4gKNaYu/UFntJK3ZKIT49q2T3HbdZZWGmcrNcrmhy/4E/k1lNZK0bu+bfoRP3ve1ylua7VqxhvLwGdgdiyRVpxfzwg3s0WOgSyOuqlZ5L/p01V8GujSiqmiVG+L1YqBLI2ajQW6I15eBLo2Q9XavGOLjwUCXRsB6WuUOao4fA10actNzS9zy2Uc4e+7FUuUD+Nkr9/Jr17++txXT0DHQpSH3q390snSY2yofbwa6NKTW0s1ikAsMdGkole1msXtFzQx0aQiV6WaxVa5WBro0ZKbnlnjmudW7WbZtmWTu1rf2qUYaFRcMugKSvmt6bon33P3QqmW2TE5w+8HL+lQjjRJb6NKQWO43X76JcDt2s2g1Bro0JLr1m9vNom7scpGGQLd+c7tZVIaBLg1Yt37ziQh+/W2vt5tFXRno0gCV6Tf/0Dt+1DBXKQa6NEBl+s0Nc5VloEsDYr+5qmagSwNydHa+4z77zbUeBro0ANNzSyydOdtxv/3mWg8DXeqz5YHQTuw313oZ6FKfrTYQar+5NsJAl/qo20Co/ebaCANd6qPVBkJ3bdtimGtDDHSpT7oNhN509SV9rI3qyECX+sCBUPWDgS71wdHZeQdC1XOlAj0iDkTEfEQsRMTNbfbvjYh7I2IuIh6OiGurr6o0ulbranEgVFXpGugRMQHcCVwDXArcEBGXthR7H3B3Zl4OHAZ+q+qKSqNqem6J6LDPgVBVqUwL/QpgITMfz8wXgLuAQy1lEvg7xeNXA6eqq6I02o7OztPuWoqBA6GqVplA3wU82fR8sdjW7Hbg5yJiETgO/Nt2LxQRRyLiREScOH369DqqK42W1Wa2JNg6V6XKBHq7vxZbGxw3AB/LzN3AtcAnImLFa2fmscycysypnTt3rr220gjpNrNl17YtfayNxkGZQF8E9jQ9383KLpV3A3cDZOZfAN8D7KiigtKo6jazxe4WVa1MoN8P7I+IiyNiM41Bz5mWMl8D3gwQET9MI9DtU9FYc2aL+q1roGfmeeBGYBZ4jMZslpMRcUdEHCyKvQf4xYh4CPgU8POZq9xTS6o5Z7ZoEDaVKZSZx2kMdjZvu7Xp8aPAm6qtmjS6nNmiQXClqNQDp5zZogEw0KWKTc8tcUG073BxZot6yUCXKrQ8VfHFNkNIzmxRrxnoUoU6TVX0ps/qBwNdqlCnvvOXMg1z9ZyBLlVo29bJttsvsu9cfWCgSxWZnlviW98+v2L75ETYd66+MNClihydnefcSysHQ1+5eZPdLeoLA12qwGpXVXz27Lk+10bjykCXNqjbVRXtP1e/GOjSBnlVRQ0LA13aoE5TFcGrKqq/DHRpgzp1qXhVRfWbgS5twPTcEn/7/Mqpina1aBBKXT5X0krLg6Gt/efbt05y23WX2TpX39lCl9ap02DoVueda0AMdGmdOg2GrjZIKvWSgS6tk9dt0bAx0KV18LotGkYGurQOXrdFw8hAl9ahUz+5123RIBno0hqtds9Q+881SAa6tAbeM1TDzECX1sB7hmqYGejSGnjPUA0zA11ag0595PadaxgY6NIa/Pjf20nrcKh95xoWBrpU0vTcEr//wBLNw6EB/PM37rK7RUPBQJdKajcgmsC9Xz49mApJLQx0qSQvxqVhVyrQI+JARMxHxEJE3NyhzDsi4tGIOBkR/6PaakqD5WIijYKuN7iIiAngTuAngEXg/oiYycxHm8rsB24B3pSZz0TEa3tVYanfXEykUVGmhX4FsJCZj2fmC8BdwKGWMr8I3JmZzwBk5tPVVlMaHBcTaVSUCfRdwJNNzxeLbc1+CPihiPhfEXFfRBxo90IRcSQiTkTEidOnHUjSaHAxkUZFmUBv13HY+rfnJmA/cBVwA/CRiNi24psyj2XmVGZO7dy5c611lQbCxUQaFWUCfRHY0/R8N3CqTZk/zMxzmfmXwDyNgJdGnouJNCrKBPr9wP6IuDgiNgOHgZmWMtPAjwNExA4aXTCPV1lRaRBcTKRR0jXQM/M8cCMwCzwG3J2ZJyPijog4WBSbBb4ZEY8C9wI3ZeY3e1VpqV9cTKRR0nXaIkBmHgeOt2y7telxAr9SfEm14WIijRJXikoduJhIo8ZAl9pwMZFGkYEuteFiIo0iA11qw8VEGkUGutSGi4k0igx0qQ0XE2kUGehSCxcTaVQZ6FILFxNpVBnoUgsXE2lUGehSCwdENaoMdKnJ9NwSf/v8+RXbHRDVKCh1LRdpHCyvDm3tP9++dZLbrrvMAVENPVvoUqHT6tCtmzcZ5hoJBrpUcDBUo85AlwoOhmrUGehSwdWhGnUGuoSrQ1UPBrqEq0NVDwa6hAOiqgcDXcIBUdWDga6x5+pQ1YUrRTXWXB2qOrGFrrHm6lDViYGuseZgqOrEQNdY27Z1su12B0M1igx0ja3puSW+9e2Vg6GTE+FgqEaSga6xdXR2nnMv5Yrtr7T/XCPKQNfY6tRP/uzZc32uiVQNA11jy8VEqptSgR4RByJiPiIWIuLmVcq9PSIyIqaqq6JUPRcTqY66BnpETAB3AtcAlwI3RMSlbcq9Cvh3wBeqrqRUpeXFRGdaula2b53k19/2evvPNbLKtNCvABYy8/HMfAG4CzjUptz7gQ8C366wflLlXEykuioT6LuAJ5ueLxbbviMiLgf2ZObnVnuhiDgSESci4sTp016WVIPhYiLVVZlAb72JC/Dd+wBExAXAfwHe0+2FMvNYZk5l5tTOnTvL11KqkIOhqqsygb4I7Gl6vhs41fT8VcCPAH8WEU8AVwIzDoxqWHmrOdVVmUC/H9gfERdHxGbgMDCzvDMzn83MHZm5LzP3AfcBBzPzRE9qLG2At5pTnXUN9Mw8D9wIzAKPAXdn5smIuCMiDva6glKVvNWc6qzU9dAz8zhwvGXbrR3KXrXxakm94YCo6syVohob03NLXBDtxvgdEFU9GOgaC8uLiV7MlRfjckBUdWGgayx0Wkw0EeHqUNWGga6x0KmP/KVMw1y1YaBrLHhnIo0DA121552JNC4MdNWedybSuDDQVXvemUjjwkBX7XkxLo0LA1215p2JNE5KLf2XRtHyYqLW+efbt05y23WX2X+u2rGFrtryzkQaNwa6assLcWncGOiqJS/EpXFkoKt2vBCXxpWBrtrxQlwaVwa6ascLcWlcGeiqHS/EpXFloKtWvBCXxpmBrlrxQlwaZwa6amN6boklL8SlMWagqxaWpyp2Yv+5xoGBrlroNFURnHuu8WGgqxZWW87v3HONCwNdtdBpquKubVsMc40NA10jz6mKUoOBrpHnVEWpwUDXSHOqovRdBrpGllMVpZcz0DWynKoovVypQI+IAxExHxELEXFzm/2/EhGPRsTDEfEnEfED1VdVerlOXS3gVEWNp66BHhETwJ3ANcClwA0RcWlLsTlgKjP/PvAZ4INVV1RqNj23RPv7ETlVUeOrTAv9CmAhMx/PzBeAu4BDzQUy897MfK54eh+wu9pqSi93dHaelfNaIMCuFo2tMoG+C3iy6flisa2TdwOfb7cjIo5ExImIOHH69OnytZSarDazJcHWucZWmUBv95dtu8YREfFzwBRwtN3+zDyWmVOZObVz587ytZQK3Wa27HJmi8bYphJlFoE9Tc93A6daC0XEW4D3Av80M5+vpnrSyzmzReqsTAv9fmB/RFwcEZuBw8BMc4GIuBz4b8DBzHy6+mpKDc5skTrrGuiZeR64EZgFHgPuzsyTEXFHRBwsih0Fvhf4vYh4MCJmOryctG7ObJFWV6bLhcw8Dhxv2XZr0+O3VFwvaQVntkirc6WoRoIzW6TuDHQNPWe2SOUY6Bp6v/pHJ53ZIpVgoGuoTc8t8cxznS+D68wW6bsMdA2t6bkl3nP3Qx33O7NFejkDXUNpud/8xWy7KBlwZovUykDXUFqt3xxg25ZJW+dSCwNdQ6dbv/mWyQluP3hZH2skjQYDXUOlW7/5RIQDoVIHBrqGRpl+8w+940cNc6kDA11Dw35zaWMMdA0F+82ljTPQNXD2m0vVKHW1RalX3jf9CJ+872vtb4FVsN9cKscWugZmem6pa5jbby6VZ6BrIJa7WVYLc/vNpbWxy0V9V6abxX5zae0MdPXN9NwSt8+c5MzZzrNZoHEHIvvNpbUz0NVzZYMcGmH+s1fuNcyldTDQ1VNluleWTUTYMpc2wEBXT6ylVQ52s0hVMNBVubW0ysFuFqkqBroqsdYW+bLtWye57brLDHOpAga6NsQgl4aHga41m55b4ujsPEtnzq75e5e7V37t+tdXXzFpzBno6mq9rfBWtsql3jLQ9TLNre+A0gObq7FVLvWHgT6mWlvdFwS81JLeVYS5rXKpfwz0EVdVi7o1zDfKIJf6r1SgR8QB4DeACeAjmfmfWva/Avg48Ebgm8DPZOYT1Va1c3gtty6r6iLopF/HWe8x+1WnTuxakQara6BHxARwJ/ATwCJwf0TMZOajTcXeDTyTmT8YEYeBDwA/U2VFl28gvHzPyebwWm5d9jrQ+nWcQR9zPXZt28JNV19ii1waoDIt9CuAhcx8HCAi7gIOAc2Bfgi4vXj8GeA3IyIyV7l9+xodnZ1f9QbC6p/lvxoMcWm4lAn0XcCTTc8XgR/rVCYzz0fEs8D3Ad9oLhQRR4AjAHv37l1TRU+tY86zqmOfuDT8ygR6tNnW2vIuU4bMPAYcA5iamlpT6/2ibVvWtZBF5Sy3uicieDHT1rc0gsoE+iKwp+n5buBUhzKLEbEJeDXw15XUsHDT1Ze8rA9dG2erW6qXMoF+P7A/Ii4GloDDwL9oKTMDvBP4C+DtwJ9W2X8OfCd0nOXSfr8takldA73oE78RmKUxbfGjmXkyIu4ATmTmDPA7wCciYoFGy/xwLyp7/eW7DCxJ6qDUPPTMPA4cb9l2a9PjbwM/XW3VJElrccGgKyBJqoaBLkk1YaBLUk0Y6JJUEwa6JNWEgS5JNWGgS1JNRMULOssfOOI08Ffr/PYdtFz4a4gMa92s19pYr7Ub1rrVrV4/kJk72+0YWKBvREScyMypQdejnWGtm/VaG+u1dsNat3Gql10uklQTBrok1cSoBvqxQVdgFcNaN+u1NtZr7Ya1bmNTr5HsQ5ckrTSqLXRJUgsDXZJqYmgDPSJ+OiJORsRLETHVsu+WiFiIiPmIuLrD918cEV+IiK9ExKcjYnOP6vnpiHiw+HoiIh7sUO6JiHikKHeiF3VpOd7tEbHUVLdrO5Q7UJzHhYi4uQ/1OhoRX46IhyPiDyJiW4dyfTlf3X7+iHhF8R4vFJ+nfb2qS9Mx90TEvRHxWPF/4N+3KXNVRDzb9P7e2u61elS/Vd+baPivxTl7OCLe0Ic6XdJ0Lh6MiL+JiF9uKdOXcxYRH42IpyPiS03bXhMR9xR5dE9EbO/wve8synwlIt655oNn5lB+AT8MXAL8GTDVtP1S4CHgFcDFwFeBiTbffzdwuHj8YeBf9aHOHwJu7bDvCWBHH8/f7cB/6FJmojh/rwM2F+f10h7X663ApuLxB4APDOp8lfn5gX8NfLh4fBj4dB/euwuBNxSPXwX8nzb1ugr4XL8+T2t5b4Brgc/TuHPilcAX+ly/CeD/0liA0/dzBvwT4A3Al5q2fRC4uXh8c7vPPfAa4PHi3+3F4+1rOfbQttAz87HMnG+z6xBwV2Y+n5l/CSwAVzQXiIgA/hnwmWLT7wLX97K+xTHfAXyql8ep2BXAQmY+npkvAHfROL89k5l/nJnni6f30bjp+KCU+fkP0fj8QOPz9Obive6ZzHwqM79YPP5/wGPAKN178RDw8Wy4D9gWERf28fhvBr6ametdib4hmfnnNG7F2az5c9Qpj64G7snMv87MZ4B7gANrOfbQBvoqdgFPNj1fZOWH/fuAM03B0a5M1f4x8PXM/EqH/Qn8cUQ8EBFHelyXZTcWf/J+tMOfeGXOZS+9i0ZLrp1+nK8yP/93yhSfp2dpfL76oujiuRz4Qpvd/yAiHoqIz0fEZf2qE93fm0F/rg7TuWE1qHP2dzPzKWj8wgZe26bMhs9bqXuK9kpE/E/g+9vsem9m/mGnb2uzrXXuZZkypZWs5w2s3jp/U2aeiojXAvdExJeL3+Trtlq9gN8G3k/j534/je6gd7W+RJvv3fA81jLnKyLeC5wHPtnhZSo/X+2q2mZbTz9LaxER3wv8PvDLmfk3Lbu/SKNL4VvF+Mg0sL8f9aL7ezPIc7YZOAjc0mb3IM9ZGRs+bwMN9Mx8yzq+bRHY0/R8N3Cqpcw3aPyZt6loVbUrU1q3ekbEJuBtwBtXeY1Txb9PR8Qf0Phzf0MBVfb8RcR/Bz7XZleZc1l5vYrBnp8E3pxF52Gb16j8fLVR5udfLrNYvM+vZuWf05WLiEkaYf7JzPxs6/7mgM/M4xHxWxGxIzN7fhGqEu9NTz5XJV0DfDEzv966Y5DnDPh6RFyYmU8V3U9PtymzSKOff9luGmOIpY1il8sMcLiYfXAxjd+w/7u5QBES9wJvLza9E+jU4q/CW4AvZ+Ziu50R8cqIeNXyYxoDg19qV7YqLX2WP9XhePcD+6MxI2gzjT9VZ3pcrwPAfwQOZuZzHcr063yV+flnaHx+oPF5+tNOv4SqUvTR/w7wWGb+5w5lvn+5Lz8irqDxf/mbvaxXcawy780M8C+L2S5XAs8udzf0Qce/lAd1zgrNn6NOeTQLvDUithddpG8ttpXX6xHfDYwU/xSN31jPA18HZpv2vZfG7IR54Jqm7ceBi4rHr6MR9AvA7wGv6GFdPwb8Usu2i4DjTXV5qPg6SaProdfn7xPAI8DDxYfpwtZ6Fc+vpTGL4qt9qtcCjX7CB4uvD7fWq5/nq93PD9xB4xcOwPcUn5+F4vP0uj6co39E40/th5vO07XALy1/zoAbi3PzEI3B5X/Y63qt9t601C2AO4tz+ghNs9R6XLetNAL61U3b+n7OaPxCeQo4V2TYu2mMu/wJ8JXi39cUZaeAjzR977uKz9oC8AtrPbZL/yWpJkaxy0WS1IaBLkk1YaBLUk0Y6JJUEwa6JNWEgS5JNWGgS1JN/H/a0A27UpG7cAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. 로지스틱 회귀 실습\n",
    "\n",
    "#### Q) 공부 시간과 어학연수 기간에 따른 시험 합격 여부 예측\n",
    "#### -> 어학연수를 7년 다녀오고, 7시간 공부하면 시험에 합격할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 데이터는\n",
    "# 공부시간      어학연수기간   시험성적\n",
    "#    1              1             0(Fail)\n",
    "#    2              0             0\n",
    "#    5              1             0\n",
    "#    2              3             1(Pass)\n",
    "#    3              3             1\n",
    "#    8             1              1\n",
    "#    10            0              1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 0.6048927307128906\n",
      "cost 값은 : 0.11616965383291245\n",
      "cost 값은 : 0.07662037760019302\n",
      "cost 값은 : 0.05687626823782921\n",
      "cost 값은 : 0.045050621032714844\n",
      "cost 값은 : 0.03721841797232628\n",
      "cost 값은 : 0.03166886046528816\n",
      "cost 값은 : 0.027540283277630806\n",
      "cost 값은 : 0.024353373795747757\n",
      "cost 값은 : 0.021821264177560806\n",
      "[[0.9379553]]\n",
      "시험에 합격 : [[0.9379553]]\n"
     ]
    }
   ],
   "source": [
    "# 1. 필요한 모듈 불러오기\n",
    "import tensorflow as tf\n",
    "\n",
    "# 2. training data set\n",
    "# x에는 공부 시간과 어학연수 기간 모두 넣기\n",
    "x_data = [[1,1],\n",
    "         [2,0],\n",
    "         [5,1],\n",
    "         [2,3],\n",
    "         [3,3],\n",
    "         [8,1],\n",
    "         [10,0]]\n",
    "# y에는 시험 통과 여부\n",
    "y_data = [[0],[0],[0],[1],[1],[1],[1]]\n",
    "\n",
    "# 3. placeholder\n",
    "X = tf.placeholder(shape = [None,2], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None,1], dtype = tf.float32)\n",
    "\n",
    "# 4. Weight, Bias 설정\n",
    "W = tf.Variable(tf.random_normal([2,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# 5. hypothesis 설정\n",
    "# y가 0, 1로 나타내어지는 데이터셋의 형태이기 때문에, S자 형태의 sigmoid 함수를 이용한다.\n",
    "logit = tf.matmul(X,W) + b\n",
    "# 가설이 되기 전 -> 행렬곱만 해준 상태.\n",
    "H = tf.sigmoid(logit)\n",
    "# tensorflow 내의 sigmoid 함수를 이용해 가설을 설정한다.\n",
    "\n",
    "# 6. cost function\n",
    "# 일반적으로 tensorflow에서 제공하는 함수를 이용한다.\n",
    "# discrete classification tasks in which each class is independent and not mutually exclusive.\n",
    "# 참고 페이지: https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits?version=stable\n",
    "cost= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                            labels = Y))\n",
    "# For brevity, let x = logits, z = labels.\n",
    "# logits에 가설 넣는 게 아니라 logit을 넣는 것.\n",
    "# label에 Y 넣으면\n",
    "# 그걸 알아서 sigmoid로 계산하고,\n",
    "# cost function으로 만든다.\n",
    "\n",
    "# 7. train\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# 8. session 생성, 변수 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 세션을 실행하는데, 변수 초기화하는 세션을 실행해라.\n",
    "\n",
    "# 9. 학습 진행\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost],\n",
    "                          feed_dict ={\n",
    "                              X : x_data,\n",
    "                              Y : y_data\n",
    "                          })\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost 값은 : {}\".format(cost_val))\n",
    "        \n",
    "# cost 값 0.02 정도까지 떨어진다. -> 이 정도면 괜찮게 학습되었다고 판단.\n",
    "\n",
    "# 10. 예측 진행(prediction)\n",
    "result = sess.run(H, feed_dict = {X : [[7,1]]})\n",
    "print(result)                 # 93퍼센트 정도 합격할 것.\n",
    "if result > 0.5 :\n",
    "    print(\"시험에 합격 : {}\".format(result))\n",
    "else:\n",
    "    print(\"시험에 불합격 : {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 로지스틱 회귀 연습문제\n",
    "\n",
    "#### Q) 대학원 입학시험에 대한 합격 여부 예측\n",
    "* 전처리 단계 : rank의 경향성\n",
    "* 이상치 처리\n",
    "\n",
    "#### A) 틀렸다! *Cost*값 중구난방이다.\n",
    "\n",
    "``` \n",
    "첫 번째 결과 : 30000, 0.01\n",
    "cost값은 : 189.8178253173828\n",
    "cost값은 : 1.7592873573303223\n",
    "cost값은 : 6.497927188873291\n",
    "cost값은 : 5.869077682495117\n",
    "cost값은 : 6.773313999176025\n",
    "cost값은 : 8.64787483215332\n",
    "cost값은 : 10.574755668640137\n",
    "cost값은 : 12.52682113647461\n",
    "cost값은 : 14.489851951599121\n",
    "cost값은 : 16.456096649169922 ```\n",
    "\n",
    "```\n",
    "두 번째 결과 : 30000, 0.1\n",
    "cost값은 : 391.9734802246094\n",
    "cost값은 : 7635.13623046875\n",
    "cost값은 : 7617.27734375\n",
    "cost값은 : 7576.896484375\n",
    "cost값은 : 7534.650390625\n",
    "cost값은 : 7491.50146484375\n",
    "cost값은 : 7475.62890625\n",
    "cost값은 : 7434.072265625\n",
    "cost값은 : 7392.486328125\n",
    "cost값은 : 7350.90234375\n",
    "```\n",
    "\n",
    "\n",
    "* minmax scale -> scale 다시 해보면?\n",
    "* 이상치 처리 방식?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 필요한 라이브러리 import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      "admit    400 non-null int64\n",
      "gre      400 non-null int64\n",
      "gpa      400 non-null float64\n",
      "rank     400 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  rank\n",
       "0        0  380.0  3.61     2\n",
       "1        1  660.0  3.67     2\n",
       "2        1  800.0  4.00     4\n",
       "3        1  640.0  3.19     1\n",
       "4        0  520.0  2.93     1\n",
       "..     ...    ...   ...   ...\n",
       "395      0  620.0  4.00     3\n",
       "396      0  560.0  3.04     2\n",
       "397      0  460.0  2.63     3\n",
       "398      0  700.0  3.65     3\n",
       "399      0  600.0  3.89     2\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 391.9734802246094\n",
      "cost값은 : 7635.13623046875\n",
      "cost값은 : 7617.27734375\n",
      "cost값은 : 7576.896484375\n",
      "cost값은 : 7534.650390625\n",
      "cost값은 : 7491.50146484375\n",
      "cost값은 : 7475.62890625\n",
      "cost값은 : 7434.072265625\n",
      "cost값은 : 7392.486328125\n",
      "cost값은 : 7350.90234375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. 데이터 준비\n",
    "\n",
    "data_df = pd.read_csv(\"./data/admission.csv\")\n",
    "display(data_df)\n",
    "\n",
    "# 2-1. EDA\n",
    "data_df.info()\n",
    "data_df.corr()\n",
    "\n",
    "rank_mapping_dict = { 4 : 1, 3 : 2, 2 : 3, 1 : 4}\n",
    "data_df[\"rank\"] = data_df[\"rank\"].map(rank_mapping_dict)\n",
    "\n",
    "data_df\n",
    "\n",
    "# 2-2. 결측치 확인 : 없음\n",
    "data_df.isnull().sum()\n",
    "\n",
    "# 2-3. 이상치 확인\n",
    "# plt.boxplot(data_df[\"gre\"]) # gre: 하위이상치 존재\n",
    "# plt.boxplot(data_df[\"gpa\"]) # gpa: 하위이상치 존재\n",
    "\n",
    "# 2-4. gre 이상치 대체\n",
    "gre_q1, gre_q3 = np.percentile(data_df[\"gre\"], [25, 75])\n",
    "iqr_gre = gre_q3 - gre_q1\n",
    "gre_lower = gre_q1 - 1.5  * iqr_gre\n",
    "gre_mean = data_df.loc[~(data_df[\"gre\"]<gre_lower)][\"gre\"].mean()\n",
    "data_df.loc[data_df[\"gre\"]<gre_lower, \"gre\"] = gre_mean\n",
    "plt.boxplot(data_df[\"gre\"])\n",
    "\n",
    "# 2-5. gpa 이상치 대체\n",
    "gpa_q1, gpa_q3 = np.percentile(data_df[\"gpa\"], [25, 75])\n",
    "iqr_gpa = gpa_q3 - gpa_q1\n",
    "gpa_lower = gpa_q1 - 1.5 * iqr_gpa\n",
    "gpa_mean = data_df.loc[~(data_df[\"gpa\"]<gpa_lower)][\"gpa\"].mean()\n",
    "data_df.loc[data_df[\"gpa\"]<gpa_lower, \"gpa\"] = gpa_mean\n",
    "plt.boxplot(data_df[\"gpa\"])\n",
    "\n",
    "# 3. 학습\n",
    "\n",
    "display(data_df)\n",
    "\n",
    "# 3-1. x, y 데이터 준비\n",
    "x_data = data_df[[\"gre\",\"gpa\",\"rank\"]].values\n",
    "y_data = data_df[[\"admit\"]].values\n",
    "\n",
    "# 3-2. placeholder\n",
    "X = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "# 3-3. W, b\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# 3-4. hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# 3-5. cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                              labels = Y))\n",
    "\n",
    "# 3-6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 3-7. sess, initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 3-8. 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = { X : x_data,\n",
    "                                                      Y : y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### minmax scale 해본다면?\n",
    "\n",
    "```\n",
    "scale 후 돌린 세 번째 결과: 좀 낫다\n",
    "cost값은 : 0.8171528577804565\n",
    "cost값은 : 0.5742185115814209\n",
    "cost값은 : 0.5737513899803162\n",
    "cost값은 : 0.5737453699111938\n",
    "cost값은 : 0.5737453103065491\n",
    "cost값은 : 0.5737453699111938\n",
    "cost값은 : 0.5737453699111938\n",
    "cost값은 : 0.5737453699111938\n",
    "cost값은 : 0.5737453699111938\n",
    "cost값은 : 0.5737453699111938\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     3\n",
       "1        1  660  3.67     3\n",
       "2        1  800  4.00     1\n",
       "3        1  640  3.19     4\n",
       "4        0  520  2.93     4\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     2\n",
       "396      0  560  3.04     3\n",
       "397      0  460  2.63     2\n",
       "398      0  700  3.65     2\n",
       "399      0  600  3.89     3\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      "admit    400 non-null int64\n",
      "gre      400 non-null int64\n",
      "gpa      400 non-null float64\n",
      "rank     400 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  rank\n",
       "0        0  380.0  3.61     2\n",
       "1        1  660.0  3.67     2\n",
       "2        1  800.0  4.00     4\n",
       "3        1  640.0  3.19     1\n",
       "4        0  520.0  2.93     1\n",
       "..     ...    ...   ...   ...\n",
       "395      0  620.0  4.00     3\n",
       "396      0  560.0  3.04     2\n",
       "397      0  460.0  2.63     3\n",
       "398      0  700.0  3.65     3\n",
       "399      0  600.0  3.89     2\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은 : 0.743462085723877\n",
      "cost값은 : 0.5740522742271423\n",
      "cost값은 : 0.5737507343292236\n",
      "cost값은 : 0.5737454295158386\n",
      "cost값은 : 0.5737453699111938\n",
      "cost값은 : 0.5737453103065491\n",
      "cost값은 : 0.5737453103065491\n",
      "cost값은 : 0.5737453103065491\n",
      "cost값은 : 0.5737453103065491\n",
      "cost값은 : 0.5737453103065491\n",
      "[[0.04361623]]\n",
      "[[0.04361623]]의 확률로, 불합격했어요.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 모듈 설치 : pip install sklearn\n",
    "\n",
    "\n",
    "# 2. 데이터 준비\n",
    "\n",
    "data_df = pd.read_csv(\"./data/admission.csv\")\n",
    "display(data_df)\n",
    "\n",
    "# 2-1. EDA\n",
    "data_df.info()\n",
    "data_df.corr()\n",
    "\n",
    "rank_mapping_dict = { 4 : 1, 3 : 2, 2 : 3, 1 : 4}\n",
    "data_df[\"rank\"] = data_df[\"rank\"].map(rank_mapping_dict)\n",
    "\n",
    "data_df\n",
    "\n",
    "# 2-2. 결측치 확인 : 없음\n",
    "data_df.isnull().sum()\n",
    "\n",
    "# 2-3. 이상치 확인\n",
    "# plt.boxplot(data_df[\"gre\"]) # gre: 하위이상치 존재\n",
    "# plt.boxplot(data_df[\"gpa\"]) # gpa: 하위이상치 존재\n",
    "\n",
    "# 2-4. gre 이상치 대체\n",
    "gre_q1, gre_q3 = np.percentile(data_df[\"gre\"], [25, 75])\n",
    "iqr_gre = gre_q3 - gre_q1\n",
    "gre_lower = gre_q1 - 1.5  * iqr_gre\n",
    "gre_mean = data_df.loc[~(data_df[\"gre\"]<gre_lower)][\"gre\"].mean()\n",
    "data_df.loc[data_df[\"gre\"]<gre_lower, \"gre\"] = gre_mean\n",
    "plt.boxplot(data_df[\"gre\"])\n",
    "\n",
    "# 2-5. gpa 이상치 대체\n",
    "gpa_q1, gpa_q3 = np.percentile(data_df[\"gpa\"], [25, 75])\n",
    "iqr_gpa = gpa_q3 - gpa_q1\n",
    "gpa_lower = gpa_q1 - 1.5 * iqr_gpa\n",
    "gpa_mean = data_df.loc[~(data_df[\"gpa\"]<gpa_lower)][\"gpa\"].mean()\n",
    "data_df.loc[data_df[\"gpa\"]<gpa_lower, \"gpa\"] = gpa_mean\n",
    "plt.boxplot(data_df[\"gpa\"])\n",
    "\n",
    "# 3. 학습\n",
    "\n",
    "display(data_df)\n",
    "\n",
    "# 3-1. x, y 데이터 준비\n",
    "x_data = data_df[[\"gre\",\"gpa\",\"rank\"]].values\n",
    "y_data = data_df[[\"admit\"]].values\n",
    "\n",
    "\n",
    "########## minmax scale ########################\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "\n",
    "# 3-2. placeholder\n",
    "X = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "# 3-3. W, b\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# 3-4. hypothesis\n",
    "logit = tf.matmul(X, W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# 3-5. cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                              labels = Y))\n",
    "\n",
    "# 3-6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "# 3-7. sess, initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 3-8. 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = { X : x_data,\n",
    "                                                      Y : y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"cost값은 : {}\".format(cost_val))\n",
    "        \n",
    "# 3-9. 예측 : 660, 3.67, rank = 2일 때 예측 : rank = 2임에 주의.\n",
    "predict_x_data = scaler.fit_transform([[660, 3.67, 3]])\n",
    "result = sess.run(H, feed_dict = {X : predict_x_data})\n",
    "print(result)\n",
    "if result > 0.5 :\n",
    "    print(f\"{result}의 확률로, 합격했어요.\")\n",
    "else:\n",
    "    print(f\"{result}의 확률로, 불합격했어요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. 정확도 측정\n",
    "* 정확도 측정했을 때, 95% 이상이어야 실생활에서 사용할 수 있다.\n",
    "\n",
    "* 1) 학습용 data set과 테스트용 data set으로 나눈다.\n",
    "    * 나누지 않고, train data set을 test에 이용하면 이미 학습했기 때문에, 과적합의 문제가 일어난다.\n",
    "* 2) predict한 결과를 알아 온다 - logistic이므로 결과는 모두 0, 1 중 하나로 나온다.\n",
    "* 3) result 변수 저장 - H > 0.5일 때 True, 아니면 False.\n",
    "* 4) tensorflow의 cast 함수를 이용해 result 값을 True일 때 1.0, False일 때 0.0으로 바꾼다.\n",
    "    * tf.cast : 논리값을 실수값으로 바꾼다.\n",
    "    * 예측값과 주어진 데이터의 값(이미 갖고 있는 Y data)이 같으면 True, 아니면 False.\n",
    "    * 각각의 True를 1, False를 0으로 바꾼다.\n",
    "* 5) 정확도 도출 : reduce_mean 함수 이용\n",
    "    * 1, 0의 값을 평균 내면, 1이 몇 개 있는지 알 수 있어서 퍼센티지 값을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연습문제 강사님 방식 + 정확도 측정하는 방법까지 함께 알아본다.\n",
    "#### 결과적으로, 이 모델은 사용할 수 없는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit  gre   gpa  rank\n",
       "0        0  380  3.61     2\n",
       "1        1  660  3.67     2\n",
       "2        1  800  4.00     4\n",
       "3        1  640  3.19     1\n",
       "4        0  520  2.93     1\n",
       "..     ...  ...   ...   ...\n",
       "395      0  620  4.00     1\n",
       "396      0  560  3.04     2\n",
       "397      0  460  2.63     1\n",
       "398      0  700  3.65     1\n",
       "399      0  600  3.89     2\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 값은 : 1.3421052694320679\n",
      "cost 값은 : 0.6070732474327087\n",
      "cost 값은 : 0.5969980955123901\n",
      "cost 값은 : 0.5941833257675171\n",
      "cost 값은 : 0.5931543707847595\n",
      "cost 값은 : 0.5926678776741028\n",
      "cost 값은 : 0.5924003720283508\n",
      "cost 값은 : 0.5922430753707886\n",
      "cost 값은 : 0.5921478867530823\n",
      "cost 값은 : 0.5920897126197815\n",
      "정확도는 0.703797459602356입니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 필요한 모듈\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2. data load\n",
    "\n",
    "df = pd.read_csv(\"./Data/admission.csv\")\n",
    "\n",
    "## 2.1. data EDA, 전처리\n",
    "\n",
    "# 1) rank\n",
    "\n",
    "# 경향성을 봤더니 rank가 음의 경향을 가진다. 그래서 rank의 방향을 바꾼다.\n",
    "# lambda 함수 이용한다.\n",
    "\n",
    "def change_rank(x):\n",
    "    if x == 4:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 2\n",
    "    elif x == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "df[\"rank\"] = df[\"rank\"].apply(lambda x : change_rank(x))\n",
    "display(df) # rank 변경됨.\n",
    "\n",
    "# 2) 결측치 : 없음.\n",
    "df.isnull().sum()\n",
    "\n",
    "# 3) 이상치: 삭제할 것 + 함수 만들어서 한 번에 처리.\n",
    "# boxplot 확인하는 게 좋지만, 애초에 그냥 함수 만들어서 처리해버리면 쉽다.\n",
    "\n",
    "def process_outlier(tmp_df, tmp):\n",
    "    q1, q3 = np.percentile(tmp, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    mask_upper = tmp > upper\n",
    "    mask_lower = tmp < lower\n",
    "    tmp_df = tmp_df.loc[~(mask_upper | mask_lower)]    # not 붙으면 가운데가 &로 변하니까 주의\n",
    "    return tmp_df\n",
    "\n",
    "df = process_outlier(df, df[\"gre\"])\n",
    "df = process_outlier(df, df[\"gpa\"])\n",
    "\n",
    "# 3. 데이터 준비\n",
    "\n",
    "# 3.1. x, y\n",
    "train_x_data = df[[\"gre\", \"gpa\", \"rank\"]].values\n",
    "train_y_data = df[\"admit\"].values.reshape(-1,1)\n",
    "\n",
    "# 3.2. scale\n",
    "train_x_data = MinMaxScaler().fit_transform(train_x_data)\n",
    "\n",
    "# 4. 머신러닝\n",
    "\n",
    "# 4.1. x, y data 준비\n",
    "train_x_data\n",
    "train_y_data\n",
    "\n",
    "# 4.2. placeholder\n",
    "X = tf.placeholder(shape = [None, 3], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "# 4.3. W, b\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = \"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "# 4.4. hypothesis\n",
    "logit = tf.matmul(X, W) +b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# 4.5. cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit,\n",
    "                                                             labels = Y))\n",
    "\n",
    "# 4.6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)\n",
    "\n",
    "# 4.7. session, initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 4.8. learning\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict = {X : train_x_data,\n",
    "                                                      Y : train_y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(f\"cost 값은 : {cost_val}\")\n",
    "\n",
    "# 4.9. 정확도 측정\n",
    "# 지금은 train test 나누지 않았으므로 train용을 사용하는데, 원래는 이러면 안 된다.\n",
    "predict = tf.cast(H > 0.5, dtype = tf.float32) # 0.5 조건으로 삼아서 실수값으로 바꿈.\n",
    "correct = tf.equal(predict, Y) # predict, Y가 같은지 비교\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32)) # correct라는 변수를 실행해서 평균낸다.\n",
    "result = sess.run(accuracy, feed_dict = {X : train_x_data,\n",
    "                                         Y : train_y_data})\n",
    "print(f\"정확도는 {result}입니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
