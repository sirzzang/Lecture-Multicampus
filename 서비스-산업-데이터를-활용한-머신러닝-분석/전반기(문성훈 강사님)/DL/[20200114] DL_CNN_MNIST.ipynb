{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_MNIST\n",
    " CNN 알고리즘을 활용해 MNIST 예측 모델을 만들어 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. module, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN 이해\n",
    "\n",
    " CNN 네트워크가 코드로 어떻게 구현되는지 알아보자. 이론이 코드로 구현되는 큰 과정은 다음과 같다.\n",
    "* image + filter\n",
    "* convolution(+ RELU) : activation을 위해 RELU 적용해야 하나, 이 단계에서는 생략한다.\n",
    "* pooling\n",
    "\n",
    "### Sample CNN\n",
    "\n",
    "* 입력 데이터 \n",
    "    - 1개의 흑백 이미지 데이터.\n",
    "    - 입력 데이터 4차원 NumPy 배열로 변환 : (1, 3, 3, 1).\n",
    "* 필터 : 임의로 설정. 예약어 주의.\n",
    "* activation map\n",
    "    - stride : 가로, 세로 방향 1.\n",
    "    - 패딩 : `VALID` or `SAME`.\n",
    "* pooling : `max_pool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]\n",
      "   [2.]\n",
      "   [3.]]\n",
      "\n",
      "  [[4.]\n",
      "   [5.]\n",
      "   [6.]]\n",
      "\n",
      "  [[7.]\n",
      "   [8.]\n",
      "   [9.]]]]\n",
      "image의 shape은 (1, 3, 3, 1)입니다. 성공했어요!\n",
      "[[[[ 1 10 -1]]\n",
      "\n",
      "  [[ 1 10 -1]]]\n",
      "\n",
      "\n",
      " [[[ 1 10 -1]]\n",
      "\n",
      "  [[ 1 10 -1]]]]\n",
      "weight의 shape은 (2, 2, 1, 3)입니다.\n",
      "========================= image, filter(kernel) 준비 끝 ========================================\n",
      "convolution의 shape은 (1, 2, 2, 3)입니다.\n",
      "convolution은 Tensor(\"Conv2D:0\", shape=(1, 2, 2, 3), dtype=float32)입니다. 계산 어떻게 되나 연습해보세요.\n",
      "[[[[ 12. 120. -12.]\n",
      "   [ 16. 160. -16.]]\n",
      "\n",
      "  [[ 24. 240. -24.]\n",
      "   [ 28. 280. -28.]]]]\n",
      "========================= convolution 끝 ========================================\n",
      "pool의 shape은 (1, 2, 2, 3)입니다. convolution과 달라졌나요?\n",
      "[[[[ 28. 280. -12.]\n",
      "   [ 28. 280. -16.]]\n",
      "\n",
      "  [[ 28. 280. -24.]\n",
      "   [ 28. 280. -28.]]]]\n",
      "========================= pool 끝 ========================================\n"
     ]
    }
   ],
   "source": [
    "# 입력데이터\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype = np.float32)\n",
    "image.shape             # 성공!\n",
    "print(image)\n",
    "print(f\"image의 shape은 {image.shape}입니다. 성공했어요!\")\n",
    "\n",
    "# filter\n",
    "weight = np.array([[[[1,10,-1]],[[1,10,-1]]],[[[1,10,-1]],[[1,10,-1]]]])\n",
    "print(weight)\n",
    "print(f\"weight의 shape은 {weight.shape}입니다.\")\n",
    "print(\"========================= image, filter(kernel) 준비 끝 ========================================\")\n",
    "\n",
    "# activation\n",
    "conv2d = tf.nn.conv2d(image, # 1) 사용할 이미지\n",
    "                      weight, # 2) 필터\n",
    "                      strides = [1,1,1,1], # 3) stride : 가운데가 중요\n",
    "                     padding = \"VALID\") # 4) 패딩 옵션 : 안하겠다.\n",
    "print(f\"convolution의 shape은 {conv2d.shape}입니다.\")\n",
    "# (1,2,2,3) : 1) 맨 앞 1은 이미지 개수, 2) 중간 (2,2)는 feature map의 shape, 3) 마지막 3은 필터 개수.\n",
    "print(f\"convolution은 {conv2d}입니다. 계산 어떻게 되나 연습해보세요.\")\n",
    "\n",
    "# session, run.\n",
    "sess = tf.Session()\n",
    "print(sess.run(conv2d)) # conv2d는 tensorflow node. 실행하여 numpy array로 뽑은 것.\n",
    "print(\"========================= convolution 끝 ========================================\")\n",
    "\n",
    "# pooling layer\n",
    "pool = tf.nn.max_pool(conv2d, # convolution에 대해 pooling 진행\n",
    "                     ksize = [1,2,2,1], # kernel size 얼마만큼씩 띠어서 pool하나? # 맨앞과 뒤의 1은 더미였다.\n",
    "                     strides = [1,1,1,1], # 1칸씩 이동할게!\n",
    "                     padding = \"SAME\") # padding 진행하겠다.\n",
    "print(f\"pool의 shape은 {pool.shape}입니다. convolution과 달라졌나요?\") # padding same 옵션 잡았으니까, shape 잡아보면 크기 같음\n",
    "print(sess.run(pool))\n",
    "print(\"========================= pool 끝 ========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 이미지 확인\n",
    "\n",
    " convolution한 결과 이미지가 원본 이미지에 비해 어떻게 다른지 확인한다. 결과적으로, 이미지를 나타내는 특징적인 픽셀만 나온다. 이를 위해 MNIST 훈련 데이터 55000개 중 하나 들고 와서 : 원본 보고 -> convolution 보고 -> pooling 과정을 거친 후 원본 이미지가 어떻게 변하는지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "conv2d 계산해보세요 몇 개일지\n",
      "convolution의 shape은 (1, 14, 14, 5)입니다. 손으로 계산해보세영여영\n",
      "pool한 결과의 shape은 (1, 7, 7, 5)입니다.\n",
      "(5, 7, 7, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a11f8bc198>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# module import\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt # 그림그려보기 위해\n",
    "\n",
    "# data load\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",\n",
    "                                 one_hot=True)\n",
    "# mnist.train.images : 55000개, 784열\n",
    "\n",
    "# check data\n",
    "img = mnist.train.images[0].reshape(28,28) # 2차원 28*28 size.\n",
    "plt.imshow(img, cmap = \"Greys\") # 원본 이미지\n",
    "\n",
    "# 해당 원본 이미지에 convolution 처리\n",
    "img = img.reshape(-1, 28, 28, 1)\n",
    "W = tf.Variable(tf.random_normal([3,3,1, 5]), name = \"filter1\") # filter\n",
    "print(\"conv2d 계산해보세요 몇 개일지\")\n",
    "conv2d = tf.nn.conv2d(img, W, strides = [1,2,2,1], padding = \"SAME\") # conv2d\n",
    "print(f\"convolution의 shape은 {conv2d.shape}입니다. 손으로 계산해보세영여영\")\n",
    "# stride가 1일 때 SAME 하면 처음과 끝이 동일하게 나온다.\n",
    "# stride가 2일 때 SAME 잡으면 2 나눠서 나온다.\n",
    "\n",
    "# convolution tensor 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) \n",
    "conv2d_result = sess.run(conv2d)\n",
    "\n",
    "# 이미지 확인 : 축 전환\n",
    "conv2d_img = np.swapaxes(conv2d_result, 0, 3)\n",
    "\n",
    "# 축 전환 후 특징 뽑아 낸 각각의 이미지 확인\n",
    "# plt.imshow(conv2d_img[0].reshape(14,14), cmap=\"Greys\")\n",
    "# plt.imshow(conv2d_img[1].reshape(14,14), cmap=\"Greys\")\n",
    "# plt.imshow(conv2d_img[2].reshape(14,14), cmap=\"Greys\")\n",
    "# plt.imshow(conv2d_img[3].reshape(14,14), cmap=\"Greys\")\n",
    "# plt.imshow(conv2d_img[4].reshape(14,14), cmap=\"Greys\")\n",
    "\n",
    "# pooling : 더 흐릿해진다.\n",
    "pool = tf.nn.max_pool(conv2d_result, \n",
    "                     ksize = [1,2,2,1],\n",
    "                     strides = [1,2,2,1]\n",
    "                     padding = \"VALID\") \n",
    "print(f\"pool한 결과의 shape은 {pool.shape}입니다.\") # 7, 7\n",
    "\n",
    "# pooling 후 이미지 확인.\n",
    "pool = sess.run(pool)\n",
    "pool_img = np.swapaxes(pool, 0, 3)\n",
    "print(pool_img.shape)\n",
    "#plt.imshow(pool_img[0].reshape(7,7), cmap=\"Greys\") : 너무 흐릿하다.\n",
    "plt.imshow(pool_img[1].reshape(7,7), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# data load\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",\n",
    "                                 one_hot= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Cost : 0.3225434124469757\n",
      "Cost : 0.17546415328979492\n",
      "Cost : 0.017594777047634125\n",
      "Cost : 0.1369365155696869\n",
      "Cost : 0.012903297320008278\n",
      "Cost : 0.02968418411910534\n",
      "Cost : 0.04002965986728668\n",
      "Cost : 0.02480500377714634\n",
      "Cost : 0.1298915296792984\n",
      "Cost : 0.029111383482813835\n",
      "정확도는 0.9850999712944031입니다.\n"
     ]
    }
   ],
   "source": [
    "# tensorflow-MNIST with CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# Graph 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Convolution Layer (Layer1)\n",
    "x_img = tf.reshape(X, [-1,28,28,1]) # 몇장인지 모르고 28,28이고 색은 그레이스케일 1\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "L1 = tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding=\"SAME\") # strides와 padding은 parameter값\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "# Layer2\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "# 이렇게 만든 data를 FC Layer에 넣어서 학습!\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64])\n",
    "#L2.shape # TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(64)])\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256]), name=\"bias3\")\n",
    "_L3 = tf.nn.relu(tf.matmul(L2, W3)+b3)\n",
    "L3 = tf.nn.dropout(_L3, keep_prob=drop_rate)\n",
    "\n",
    "# Layer 4\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,256],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([256]), name=\"bias4\")\n",
    "_L4 = tf.nn.relu(tf.matmul(L3, W4)+b4)\n",
    "L4 = tf.nn.dropout(_L4, keep_prob=drop_rate)\n",
    "\n",
    "# Layer 5\n",
    "W5 = tf.get_variable(\"weight5\", shape=[256,10],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]), name=\"bias5\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(L4, W5)+b5\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                                    labels = Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.005).minimize(cost)\n",
    "\n",
    "# Session & reset\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 50\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict = { X : batch_x,\n",
    "                                                              Y : batch_y,\n",
    "                                                              drop_rate : 0.75})\n",
    "    if step % 5 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "        \n",
    "# 정확도 측정\n",
    "predict = tf.argmax(H, 1)\n",
    "is_correct = tf.equal(predict, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, dtype = tf.float32))\n",
    "result = sess.run(accuracy,\n",
    "                 feed_dict = {X : mnist.test.images,\n",
    "                             Y : mnist.test.labels,\n",
    "                             drop_rate : 1})\n",
    "print(f\"정확도는 {result}입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4차원 `ndarray`를 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample = np.array([1]) # (1, ) : 1차원, 스칼라\n",
    "#sample = np.array([[1,2]]) # (1, 2) : 1행 2열, 2차원 벡터 # [[1 2]]\n",
    "sample = np.array([[1],[2]]) # (2, 1) : 2행 1열, 2차원 벡터 \n",
    "# [[1]\n",
    "# [2]]\n",
    "print(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 3, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어떻게 만드나? 끝에서부터 만든다\n",
    "# (3,1) 짜리가 3개 있으면 [3,3,1]\n",
    "# 그걸 전체를 배열로 잡아서 1개로 넣으면 (1,3,3,1)\n",
    "# image = np.array([[1],[1],[1]]) # 이게 (3,1)짜리\n",
    "# image = np.array([[[1],[1],[1]],[[1],[1],[1]],[[1],[1],[1]]]) # 여기까지 하면 (3,1)짜리가 3개 있음 : (3,3,1)\n",
    "image = np.array([[[[1],[1],[1]],[[1],[1],[1]],[[1],[1],[1]]]]) # 위에까지 한 걸 하나로 묶어라\n",
    "image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
